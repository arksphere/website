---
title: HAMi
description: >-
  Discover HAMi, the middleware that simplifies AI resource management across
  diverse hardware, enhancing performance and cluster utilization in
  cloud-native environments.
date: 2025-10-10T05:05:15.239Z
oss_date: 2021-09-14T11:51:49.000Z
website: 'https://project-hami.io'
github: 'https://github.com/Project-HAMi/HAMi'
author: Project-HAMi
tags:
  - inference
featured: false
thumbnail: 'https://opengraph.githubassets.com/1/Project-HAMi/HAMi'
category: Inference
---

## Overview

HAMi (Heterogeneous AI Computing Virtualization Middleware) unifies management and scheduling of AI compute resources across heterogeneous accelerators and cluster environments. By abstracting hardware differences and offering consistent resource interfaces and virtualization, HAMi simplifies orchestration of GPUs, NPUs, Ascend devices and improves cluster utilization.

## Key Features

- Unified resource abstraction across different vendors and device types.
- Heterogeneous scheduling and isolation with topology- and performance-aware policies.
- Kubernetes-friendly integration for cloud-native deployments and multi-tenant scenarios.
- Open-source (Apache-2.0), enabling community collaboration and enterprise adoption.

## Use Cases

- Large-scale training and inference clusters with mixed accelerators.
- Cloud-native deployments requiring accelerator virtualization for AI services.
- Edge and hybrid-cloud scenarios coordinating diverse device fleets for cost and performance balance.

## Technical Highlights

- Virtualization middleware architecture that exposes programmable interfaces to hide hardware differences.
- Pluggable backends and adapters for vendor drivers and telemetry collectors.
- Active open-source community and ecosystem integrations for cross-platform interoperability.
