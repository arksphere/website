---
title: Jina Serve
description: >-
  Jina Serve is a cloud-native framework for building and deploying multimodal
  AI services, supporting gRPC/HTTP/WebSocket, dynamic batching, elastic scaling
  and multiple deployment modes.
date: 2025-10-10T08:32:58.246Z
oss_date: 2020-02-13T17:04:44.000Z
website: 'https://jina.ai/serve'
github: 'https://github.com/jina-ai/serve'
author: Jina AI
tags: []
featured: false
thumbnail: 'https://opengraph.githubassets.com/1/jina-ai/serve'
category: AI Infra
---

## Overview

Jina Serve is a cloud-native framework for building and deploying multimodal AI services. It supports gRPC, HTTP and WebSocket protocols, dynamic batching, and elastic scaling. The framework focuses on production-readiness, observability and container-native deployments.

## Key features

- Support for gRPC/HTTP/WebSocket with streaming output.
- Built-in replicas/shards, dynamic batching and deployment tooling for scaling.
- Integrations with container platforms, Kubernetes and Jina Cloud for production deployments.

## Use cases

Suitable for high-throughput, low-latency inference services, pipeline orchestration, model serving and enterprise deployments across recommendation, retrieval, generative and multimodal inference scenarios.

## Technical details

Implemented in Python, Serve introduces abstractions like Executor, Deployment and Flow, supports plugin backends and emphasizes engineering practices, observability and integration with tracing/monitoring systems.
