---
title: ONNX Runtime
description: ONNX Runtime is a cross-platform, high-performance machine learning inference and training accelerator that runs models exported from PyTorch, TensorFlow/Keras and traditional ML libraries across diverse hardware.
date: 2025-11-28T02:26:44.145Z
oss_date: 2017-05-01T00:00:00.000Z
website: https://onnxruntime.ai
github: https://github.com/microsoft/onnxruntime
author: Microsoft
tags:
  - inference
featured: false
thumbnail: https://opengraph.githubassets.com/1/microsoft/onnxruntime
category: Inference
---

## Overview

ONNX Runtime, maintained by Microsoft, is a cross-platform accelerator for model inference and training. It improves performance through graph optimizations and hardware integrations, enabling efficient execution of models exported from PyTorch, TensorFlow/Keras and classical ML libraries across CPUs, GPUs and other accelerators.

## Key features

- Cross-platform support and hardware acceleration for various backends.
- Graph-level transformations and optimizations for better runtime performance.
- Support for both inference and distributed training acceleration.

## Use cases

- Production model serving with reduced latency and increased throughput.
- Heterogeneous hardware deployments to optimize cost and performance.
- Large-scale batch inference and preprocessing for ML pipelines.

## Technical notes

- Native ONNX ecosystem compatibility and extensive deployment examples to simplify integration.
